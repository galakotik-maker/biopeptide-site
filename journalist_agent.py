import json
import os
import re
import shutil
from datetime import datetime
from typing import Optional

from dotenv import load_dotenv

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None


BP_PLUS_PROMPT = """–¢—ã ‚Äî –í–µ–¥—É—â–∏–π –Ω–∞—É—á–Ω—ã–π –æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å BioPeptidePlus. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–∏—Å–∞—Ç—å –ø—Ä–µ–º–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≤–∫–ª–∞–¥–∫–∏ 'BP+ View'.

–¢–æ–Ω: –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –¥–æ—Ä–æ–≥–æ–π ('Quiet Luxury'), –º–µ—Ç–∞—Ñ–æ—Ä–∏—á–Ω—ã–π. –¢—ã –æ–±—ä—è—Å–Ω—è–µ—à—å —Å–ª–æ–∂–Ω—ã–µ –±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã (—Ç–µ–ª–æ–º–µ—Ä—ã, —ç–∫—Å–ø—Ä–µ—Å—Å–∏—è –≥–µ–Ω–æ–≤) —á–µ—Ä–µ–∑ –ø–æ–Ω—è—Ç–Ω—ã–µ –æ–±—Ä–∞–∑—ã (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –∫–ª—é—á–∏, —Ä–µ–º–æ–Ω—Ç).

–°–¢–†–û–ì–û–ï –¢–†–ï–ë–û–í–ê–ù–ò–ï –ö –§–û–†–ú–ê–¢–£:
–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Å–ª–µ–¥—É—é—â–∏–µ –º–∞—Ä–∫–µ—Ä—ã (—Ä–æ–≤–Ω–æ –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ):

### TITLE: <–¢–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞>
### QUOTE: <–¢–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã>
### ESSENCE: <–¢–µ–∫—Å—Ç —Å—É—Ç–∏>
### BENEFITS: (–¥–∞–ª–µ–µ —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ üî∏)
### RECOMMENDATION: <–¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏>

–û—Å—Ç–∞–ª—å–Ω–æ–µ (–≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ, –¥–µ—Ç–∞–ª–∏, –Ω–∞—É—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç) –ø–∏—à–∏ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏.
–°–ø–∏—Å–æ–∫ BENEFITS –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ 3-4 –ø—É–Ω–∫—Ç–∞, –∫–∞–∂–¥—ã–π –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Å–∏–º–≤–æ–ª–∞ üî∏."""

DATA_FILE_PATH = os.path.join(
    os.getcwd(),
    "legal-guard-regtech-master",
    "frontend",
    "src",
    "data",
    "journalData.ts",
)


def _generate_with_openai(prompt: str, user_input: str) -> Optional[str]:
    if OpenAI is None:
        return None

    api_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not api_key:
        return None

    client = OpenAI(api_key=api_key)
    response = client.chat.completions.create(
        model=os.getenv("NEWS_MODEL", "gpt-4o-mini"),
        temperature=0.6,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_input},
        ],
    )
    if not response.choices:
        return None
    return (response.choices[0].message.content or "").strip()


def create_draft(topic: str, raw_data: str) -> str:
    user_input = (
        f"–¢–µ–º–∞: {topic}\n\n"
        f"–°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:\n{raw_data}\n\n"
        "–°—Ñ–æ—Ä–º–∏—Ä—É–π –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ."
    )
    generated = _generate_with_openai(BP_PLUS_PROMPT, user_input)
    if generated:
        return generated

    # Fallback if OpenAI key is missing.
    sentences = [part.strip() for part in re.split(r"[.!?]\s+", raw_data) if part.strip()]
    quote = sentences[0] if sentences else raw_data.strip()
    essence = sentences[1] if len(sentences) > 1 else raw_data.strip()
    title = topic.strip() or "–ù–æ–≤—ã–π –æ–±–∑–æ—Ä BioPeptidePlus"
    benefits = [
        "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –±–∏–æ—Ä–∏—Ç–º–æ–≤ –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞",
        "–£—Å–∏–ª–µ–Ω–∏–µ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Ç–∫–∞–Ω–µ–π",
        "–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏ –æ—Ä–≥–∞–Ω–∏–∑–º–∞",
    ]
    recommendation = (
        "–ö–æ–º–∞–Ω–¥–∞ BioPeptidePlus —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—É—é —Å—Ö–µ–º—É –ø–æ–¥ —Ü–µ–ª–∏ –∏ —Å—Ç–∞—Ç—É—Å –∫–ª–∏–µ–Ω—Ç–∞. "
        "–ó–∞–ø—Ä–æ—Å–∏—Ç–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞."
    )
    return (
        f"### TITLE: {title}\n\n"
        f"{raw_data.strip()}\n\n"
        f"### QUOTE: {quote}\n\n"
        f"### ESSENCE: {essence}\n\n"
        "### BENEFITS:\n"
        + "\n".join(f"üî∏ {item}" for item in benefits)
        + "\n\n"
        f"### RECOMMENDATION: {recommendation}"
    )


def save_post(content: str, filename: str) -> str:
    output_dir = os.path.join(os.getcwd(), "content_queue")
    os.makedirs(output_dir, exist_ok=True)
    safe_name = filename.strip() or "bp_plus_post.md"
    if not safe_name.endswith(".md"):
        safe_name += ".md"
    path = os.path.join(output_dir, safe_name)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return path


def _extract_title(text: str) -> str:
    match = re.search(r"^###\s*TITLE:\s*(.+)$", text, flags=re.MULTILINE)
    return match.group(1).strip() if match else ""


def _extract_quote(text: str) -> str:
    match = re.search(r"^###\s*QUOTE:\s*(.+)$", text, flags=re.MULTILINE)
    return match.group(1).strip() if match else ""


def _extract_essence(text: str) -> str:
    match = re.search(r"^###\s*ESSENCE:\s*(.+)$", text, flags=re.MULTILINE)
    return match.group(1).strip() if match else ""


def _extract_benefits(text: str) -> list[str]:
    match = re.search(
        r"^###\s*BENEFITS:\s*(.*?)(?=^###\s*RECOMMENDATION:|\Z)",
        text,
        flags=re.MULTILINE | re.DOTALL,
    )
    if not match:
        return []
    block = match.group(1).strip()
    raw_items = re.split(r"üî∏", block)
    items = [item.strip(" -\n\t\r") for item in raw_items if item.strip(" -\n\t\r")]
    return items


def _extract_recommendation(text: str) -> str:
    match = re.search(r"^###\s*RECOMMENDATION:\s*(.+)$", text, flags=re.MULTILINE)
    return match.group(1).strip() if match else ""


def _build_description(title: str, intro: str, quote: str, essence: str, benefits: list[str], recommendation: str) -> str:
    parts = []
    if title:
        parts.append(f"## {title}")
    if intro:
        parts.append(intro)
    if quote:
        parts.append(f"> {quote}")
    if essence:
        parts.append("## –°—É—Ç—å")
        parts.append(essence)
    if benefits:
        parts.append("## –ü–æ–ª—å–∑–∞")
        parts.append("\n".join(f"- {item}" for item in benefits))
    if recommendation:
        parts.append("## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è")
        parts.append(recommendation)
    return "\n\n".join(parts).strip()


def parse_markdown_to_article(content: str) -> dict:
    title = _extract_title(content)
    quote = _extract_quote(content)
    essence = _extract_essence(content)
    benefits = _extract_benefits(content)
    recommendation = _extract_recommendation(content)
    date_value = datetime.now().strftime("%Y-%m-%d")
    expert_view = essence or "–ö—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä –º–µ—Ö–∞–Ω–∏–∑–º–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤."
    lite_view = f"{title}. {benefits[0]}" if title and benefits else "–ö–æ—Ä–æ—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —á—Ç–µ–Ω–∏—è."
    description = _build_description(title, "", quote, essence, benefits, recommendation)

    return {
        "id": f"bpplus-{int(datetime.now().timestamp())}",
        "title": title,
        "quote": quote,
        "essence": essence,
        "benefits": benefits,
        "recommendation": recommendation,
        "date": date_value,
        "expert_view": expert_view,
        "lite_view": lite_view,
        "description": description,
    }


def _ensure_data_file() -> None:
    if os.path.exists(DATA_FILE_PATH):
        return
    os.makedirs(os.path.dirname(DATA_FILE_PATH), exist_ok=True)
    template = (
        "export type JournalArticle = {\n"
        "  id: string\n"
        "  title: string\n"
        "  quote: string\n"
        "  essence: string\n"
        "  benefits: string[]\n"
        "  recommendation: string\n"
        "  date: string\n"
        "  expert_view: string\n"
        "  lite_view: string\n"
        "  description: string\n"
        "}\n\n"
        "export const journalData: JournalArticle[] = [\n"
        "]\n"
    )
    with open(DATA_FILE_PATH, "w", encoding="utf-8") as f:
        f.write(template)


def publish_to_site(article_object: dict) -> str:
    _ensure_data_file()
    backup_path = DATA_FILE_PATH + ".bak"
    shutil.copyfile(DATA_FILE_PATH, backup_path)

    with open(DATA_FILE_PATH, "r", encoding="utf-8") as f:
        content = f.read()

    marker = "export const journalData: JournalArticle[] = ["
    if marker not in content:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω –º–∞—Å—Å–∏–≤ journalData –≤ —Ñ–∞–π–ª–µ.")

    insert_pos = content.find(marker) + len(marker)
    article_json = json.dumps(article_object, ensure_ascii=False, indent=2)
    indented = "\n".join(f"  {line}" if line.strip() else line for line in article_json.splitlines())
    new_content = content[:insert_pos] + "\n" + indented + ",\n" + content[insert_pos:]

    with open(DATA_FILE_PATH, "w", encoding="utf-8") as f:
        f.write(new_content)

    return DATA_FILE_PATH


def main() -> None:
    load_dotenv()
    topic = "–ü–µ–ø—Ç–∏–¥—ã –¥–ª—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞"
    raw_data = (
        "–¢–∏–º–∞–ª–∏–Ω ‚Äî –ø–µ–ø—Ç–∏–¥–Ω—ã–π –±–∏–æ—Ä–µ–≥—É–ª—è—Ç–æ—Ä —Ç–∏–º—É—Å–∞. "
        "–í –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –æ—Ç–º–µ—á–∞–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –¢-–∫–ª–µ—Ç–æ—á–Ω–æ–≥–æ –∑–≤–µ–Ω–∞ "
        "–∏ –ø–æ–≤—ã—à–µ–Ω–∏–µ —Ä–µ–∑–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ —Å –∏–º–º—É–Ω–æ–¥–µ—Ñ–∏—Ü–∏—Ç–Ω—ã–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏."
    )
    content = create_draft(topic, raw_data)
    saved_path = save_post(content, "bp_plus_immunity")
    print(f"–ì–æ—Ç–æ–≤–æ. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {saved_path}")
    article_object = parse_markdown_to_article(content)
    data_path = publish_to_site(article_object)
    print(f"–°—Ç–∞—Ç—å—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã–µ —Å–∞–π—Ç–∞: {data_path}")


if __name__ == "__main__":
    main()
